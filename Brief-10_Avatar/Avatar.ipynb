{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "destroyed-binary",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "latent_dim = 32\n",
    "height = 32\n",
    "width = 32\n",
    "channels = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biological-least",
   "metadata": {},
   "source": [
    "## The generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fantastic-paradise",
   "metadata": {},
   "source": [
    "#### Transforms the input into a 16 × 16 128-channel feature map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "selective-crossing",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_input = keras.Input(shape=(latent_dim,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cloudy-drunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Dense(128 * 16 * 16)(generator_input)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Reshape((16, 16, 128))(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "material-immune",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x) \n",
    "x = layers.LeakyReLU()(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southern-assist",
   "metadata": {},
   "source": [
    "#### Upsamples to 32 × 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fitting-spencer",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dietary-feeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Conv2D(channels, 7, activation='tanh', padding='same')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "spectacular-egypt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32768)             1081344   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 16, 16, 256)       819456    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 32, 32, 256)       1048832   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 3)         37635     \n",
      "=================================================================\n",
      "Total params: 6,264,579\n",
      "Trainable params: 6,264,579\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = keras.models.Model(generator_input, x)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-alloy",
   "metadata": {},
   "source": [
    "## The discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ultimate-balloon",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_input = layers.Input(shape=(height, width, channels))\n",
    "x = layers.Conv2D(128, 3)(discriminator_input)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "x = layers.Dropout(0.4)(x)\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "human-quest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 30, 30, 128)       3584      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 30, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 6, 6, 128)         262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 2, 2, 128)         262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 790,913\n",
      "Trainable params: 790,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = keras.models.Model(discriminator_input, x)\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "inappropriate-divide",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator_optimizer = keras.optimizers.RMSprop(\n",
    "lr=0.0008,\n",
    "clipvalue=1.0,\n",
    "decay=1e-8)\n",
    "\n",
    "discriminator.compile(optimizer=discriminator_optimizer,\n",
    "loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chicken-switch",
   "metadata": {},
   "source": [
    "## Adversarial network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "distinct-agent",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.trainable = False\n",
    "gan_input = keras.Input(shape=(latent_dim,))\n",
    "gan_output = discriminator(generator(gan_input))\n",
    "gan = keras.models.Model(gan_input, gan_output)\n",
    "\n",
    "gan_optimizer = keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=1e-8)\n",
    "gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boolean-canadian",
   "metadata": {},
   "source": [
    "## Implementing GAN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "recreational-grenada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.preprocessing import image\n",
    "#Loads CIFAR10 data\n",
    "#(x_train, y_train), (_, _) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "motivated-afternoon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1731 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset = keras.preprocessing.image_dataset_from_directory(\n",
    "    \"/home/pierre-etienne/Documents/git-workspace/simplon/Brief-10_Avatar/cartoon100/\", label_mode=None, image_size=(height, width), batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-folks",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "critical-charm",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: (None, 32, 32, 3), types: tf.float32>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "hired-frequency",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda x: x / 255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "comfortable-delaware",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for x in dataset:\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow((x.numpy() * 255).astype(\"int32\")[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "loving-access",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DatasetV2.as_numpy_iterator of <MapDataset shapes: (None, 32, 32, 3), types: tf.float32>>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.as_numpy_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "likely-adjustment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "for img in dataset.take(1):\n",
    "    print(img.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "suspended-polyester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "(1731, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.empty(shape=(0, height, width, 3))\n",
    "print(x_train)\n",
    "#y_train = np.empty(shape=(0, height, width, 3))\n",
    "for elt in dataset.as_numpy_iterator():\n",
    "    x_train = np.concatenate((x_train, elt), axis=0)\n",
    "    #y_train = np.concatenate((y_train, elt[1]), axis=0)\n",
    "\n",
    "print(x_train.shape)\n",
    "#print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "together-territory",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 10000\n",
    "batch_size = 20\n",
    "save_dir = '/home/pierre-etienne/Documents/git-workspace/simplon/Brief-10_Avatar/img_gen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "vertical-hydrogen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss: 0.6980849504470825\n",
      "adversarial loss: 0.6771527528762817\n",
      "discriminator loss: 0.6706122159957886\n",
      "adversarial loss: 0.7817580699920654\n",
      "discriminator loss: 0.5708764791488647\n",
      "adversarial loss: 1.3922231197357178\n",
      "discriminator loss: 0.647482693195343\n",
      "adversarial loss: 1.4216428995132446\n",
      "discriminator loss: 0.7313162684440613\n",
      "adversarial loss: 1.5487470626831055\n",
      "discriminator loss: 0.6832273602485657\n",
      "adversarial loss: 0.8609954118728638\n",
      "discriminator loss: 0.45002493262290955\n",
      "adversarial loss: 1.9948755502700806\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-fc12ab3cf7dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mrandom_latent_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mmisleading_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0ma_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_latent_vectors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmisleading_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1725\u001b[0m                                                     class_weight)\n\u001b[1;32m   1726\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1727\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1729\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = 0\n",
    "for step in range(iterations):\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size,latent_dim))\n",
    "    generated_images = generator.predict(random_latent_vectors)\n",
    "    \n",
    "    stop = start + batch_size\n",
    "    real_images = x_train[start: stop]\n",
    "    combined_images = np.concatenate([generated_images, real_images])\n",
    "    \n",
    "    labels = np.concatenate([np.ones((batch_size, 1)),\n",
    "    np.zeros((batch_size, 1))])\n",
    "    labels += 0.05 * np.random.random(labels.shape)\n",
    "    \n",
    "    d_loss = discriminator.train_on_batch(combined_images, labels)\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size,latent_dim))\n",
    "    misleading_targets = np.zeros((batch_size, 1))\n",
    "    a_loss = gan.train_on_batch(random_latent_vectors,misleading_targets)\n",
    "    start += batch_size\n",
    "    if start > len(x_train) - batch_size:\n",
    "        start = 0\n",
    "    if step % 100 == 0:\n",
    "        gan.save_weights('gan.h5')\n",
    "        print('discriminator loss:', d_loss)\n",
    "        print('adversarial loss:', a_loss)\n",
    "        img = image.array_to_img(generated_images[0] * 255., scale=False)\n",
    "        img.save(os.path.join(save_dir,'generated_frog' + str(step) + '.png'))\n",
    "        img = image.array_to_img(real_images[0] * 255., scale=False)\n",
    "        img.save(os.path.join(save_dir,'real_frog' + str(step) + '.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identical-barcelona",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectible-situation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finnish-thong",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
